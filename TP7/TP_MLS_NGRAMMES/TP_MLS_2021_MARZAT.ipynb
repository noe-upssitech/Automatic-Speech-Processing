{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP N°6 MODELES DE LANGAGE STATISTIQUES\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sauvegardez le fichier en mettant votre NOM dans le nom du notebook. Ce document servira de compte rendu de TP et devra être déposé sur moodle à la fin de la séance. \n",
    "\n",
    "Après avoir récupéré et lu le sujet, répondre à chacune des questions posées en : \n",
    "1) Récupérant la commande exécutée sous ubuntu ainsi que la trace associée \n",
    "2) Commentant le résultat et/ou en apportant des éléments de réponses dans la zone de texte dédiée"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RAPPELS: les commandes à utiliser sont des lignes de commandes Unix (cf 1A). Les mécanismes de redirection sont donc utilisés pour \n",
    "(1) envoyer des données en entrée de la commande (<) (2) sauvegarder des données de sortie dans un fichier (>) (3) et \n",
    "envoyer le résultat d’une commande à la commande suivante (|). Les [] indiquent que le contenu est optionnel et que la valeur indiquée est \n",
    "la valeur par défaut. Ne pas inscrire explicitement les [] dans les commandes ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPRENTISSAGE DES MODELES DE LANGAGE N-GRAMMES"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Génération de la liste de mots et calcul du nombre d’occurrences\n",
    "\n",
    "QUESTION 1 : En utilisant l’ensemble des fichiers dédiés à l’apprentissage (CORPUS_APP), \n",
    "utiliser l’outil text2wfreq pour générer la liste des mots présents dans ces fichiers ainsi que leur nombre d’occurrences (fichier .wfreq).\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# text2wfreq \t[ -hash 1000000 ] [ -verbosity 2 ] < .text     > .wfreq\n",
    "# exécuter la commande dans un terminal, copier coller la commande et la trace et copier coller le début (10 premières # lignes commande head) \n",
    "et la fin du fichier généré (10 dernières lignes commande tail). Trop long sinon \n",
    "\n",
    "text2wfreq < concat.tlm1 > occ.wfreq\n",
    "text2wfreq : Reading text from standard input...\n",
    "text2wfreq : Done.\n",
    "\n",
    "A 1\n",
    "E 1\n",
    "J 2\n",
    "accompagn�s 1\n",
    "U 4\n",
    "V 1\n",
    "X 1\n",
    "a 158\n",
    "c 1\n",
    "d 1\n",
    "\n",
    "courageuse 1\n",
    "majoritaire 1\n",
    "combattu 1\n",
    "globale 1\n",
    "r�gles 3\n",
    "remodeler 1\n",
    "doivent 5\n",
    "optimistes 1\n",
    "Gr�gori 1\n",
    "d�plaire 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 2 : A l’aide de la commande unix sort, trier la liste de façon à la classer les mots par nombres d’occurrences décroissants.\n",
    "Quels sont les mots les plus fréquents ? A quoi correspondent-ils et pourquoi ? \n",
    "\n",
    "sort -n -r -k2  < occ.wfreq > occ_sorted.wfreq\n",
    "\n",
    "<S> 1277\n",
    "</S> 1277\n",
    "de 1073\n",
    "la 701\n",
    "le 611\n",
    "l' 500\n",
    "et 456\n",
    "les 454\n",
    "� 444\n",
    "en 335\n",
    "\n",
    "Abbas 1\n",
    "abattre 1\n",
    "abasourdie 1\n",
    "abandonner 1\n",
    "ab 1\n",
    "A86 1\n",
    "A4 1\n",
    "A13 1\n",
    "A11 1\n",
    "A 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Génération du vocabulaire\n",
    "\n",
    "QUESTION 3 : Utiliser l’outil wfreq2vocab pour obtenir la liste des mots distincts correspondant au vocabulaire extrait de ce corpus d’apprentissage (fichier .vocab). Examinez cette liste.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# wfreq2vocab \t[ -top 20000 | -gt 10] [ -records 1000000 ] [ -verbosity 2]  < .wfreq     > .vocab\n",
    "# exécuter la commande dans un terminal, copier coller la commande et la trace et copier coller le début (10 premières # lignes commande head) et la fin du \n",
    "fichier généré (10 dernières lignes commande tail). Trop long sinon \n",
    "\n",
    "wfreq2vocab < occ.wfreq > vocabulaire.vocab\n",
    "wfreq2vocab : Will generate a vocabulary containing the most\n",
    "              frequent 20000 words. Reading wfreq stream from stdin...\n",
    "wfreq2vocab : Done\n",
    "\n",
    "## Vocab generated by v2 of the CMU-Cambridge Statistcal\n",
    "## Language Modeling toolkit.\n",
    "##\n",
    "## Includes 4797 words ##\n",
    "(et)\n",
    "-ce\n",
    "-elle\n",
    "-elles\n",
    "-il\n",
    "-ils\n",
    "\n",
    "�vocation\n",
    "�voquant\n",
    "�voquent\n",
    "�voquer\n",
    "�voqueront\n",
    "�voqu�\n",
    "�voqu�e\n",
    "�v�nement\n",
    "�tes\n",
    "�tre"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Liste des bigrammes et trigrammes et nombres d’occurrences associés\n",
    "\n",
    "QUESTION 4 : Utiliser l’outil text2wngram pour générer l’ensemble des paires de mots présentes dans le corpus d’apprentissage (fichier .wngram) \n",
    "et compter leur nombre d’occurrences. \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# text2wngram [ -n 3 ] [ -temp /usr/tmp/ ][ -chars n ] [ -words m ][ -gzip | -compress ] [ -verbosity 2 ] < .text     #  > .wngram\n",
    "# exécuter la commande dans un terminal, copier coller la commande et la trace et copier coller le début (10 premières # lignes commande head) \n",
    "et la fin du fichier généré (10 dernières lignes commande tail). Trop long sinon \n",
    "\n",
    "\n",
    "text2wngram < concat.tlm1 > ngram.wngram\n",
    "text2wngram\n",
    "n = 3\n",
    "Number of words in buffer = 9090909\n",
    "Number of chars in buffer = 63636363\n",
    "Max number of files open at once = 20\n",
    "Temporary directory = /usr/tmp/\n",
    "Allocated 63636363 bytes to text buffer.\n",
    "Allocated 72727272 bytes to pointer array.\n",
    "Reading text into buffer...\n",
    "Reading text into the n-gram buffer...\n",
    "20,000 words processed for each \".\", 1,000,000 for each line.\n",
    ".\n",
    "Sorting pointer array...\n",
    "Writing out temporary file /usr/tmp/text2wngram.tmp.noe-Lenovo-Legion-Y530-15ICH.23907.1...\n",
    "rr_fopen: problems opening /usr/tmp/text2wngram.tmp.noe-Lenovo-Legion-Y530-15ICH.23907.1 for \"w\"."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Quels sont les bigrammes les plus fréquents ? A quoi correspondent-ils ? \n",
    "\n",
    "Réponse ..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 5 : Utiliser l’outil text2idngram pour générer une autre version de cette liste (fichier .idngram) et comparer le résultat avec le précédent. Ne pas oublier l’option (-write_ascii) pour générer le résultat sous forme ascii et non binaire plus difficile à lire mais plus efficace en terme de traitement …"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# text2idngram -vocab .vocab [ -buffer 100 ] [ -temp /usr/tmp/ ] [ -files 20 ] [ -gzip | -compress ] [ -n 3 ] \n",
    "# [ -write_ascii ] [ -fof_size 10 ] [ -verbosity 2 ]< .text > .idngram \n",
    "\n",
    "# exécuter la commande dans un terminal, copier coller la commande et la trace et copier coller le début (10 premières # lignes commande head) et la fin du fichier généré (10 dernières lignes commande tail). Trop long sinon \n",
    "..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 6 : Examinez la trace affichée pendant l’exécution de la commande et commentez les éléments qui vous semblent significatifs.\n",
    "\n",
    "Relancer sans l’option -write_ascii pour obtenir une version binaire à utiliser par la suite (question 8).  \n",
    " Commande + trace"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 7 : Reprendre les mêmes étapes (Q4, Q5 et Q6) mais générer les fichiers correspondants aux triplets de mots.\n",
    "Ajouter les cellules (text brut) nécessaires. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 8 : A partir du fichier .idngram binaire généré précédemment, construire un modèle de langage bigramme pour chaque méthode de prélèvement proposée. Utiliser l’outil idngram2lm et l’option –arpa pour générer un fichier au format ARPA (.arpa). "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# idngram2lm -idngram .idngram\n",
    "#           -vocab .vocab\n",
    "#           -arpa .arpa | -binary .binlm\n",
    "#         [ -context .ccs ]\n",
    "#         [ -calc_mem | -buffer 100 | -spec_num y ... z ]\n",
    "#         [ -vocab_type 1 ][ -oov_fraction 0.5 ]\n",
    "#         [ -linear | -absolute | -good_turing | -witten_bell ]\n",
    "#         [ -disc_ranges 1 7 7 ] [ -cutoffs 0 ... 0 ]\n",
    "#         [ -min_unicount 0 ][ -zeroton_fraction 1.0 ]\n",
    "#         [ -ascii_input | -bin_input ][ -n 3 ]  \n",
    "#         [ -verbosity 2 ] [ -four_byte_counts ]\n",
    "#         [ -two_byte_bo_weights\n",
    "#         [ -min_bo_weight -3.2 ] [ -max_bo_weight 2.5 ] \n",
    "#            [ -out_of_range_bo_weights 10000 ] ]\n",
    "\n",
    "Remarque : vous pouvez consulter la documentation section « Discounting strategies » pour voir les détails concernant les méthodes de prélèvement et calcul du discount ratio (delta ou d(r)). \n",
    "\n",
    "# exécuter la commande dans un terminal, copier coller la commande et la trace \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Quelles informations sont données dans la trace. Quelles sont celles qui vous paraissent significatives. Comparer les valeurs obtenues lors de la génération des différents modèles.\n",
    "Commentez ici"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 9 : Reprendre l’étape précédente (Q8) pour générer un modèle de langage trigramme avec chacune des méthodes de prélèvement disponibles. \n",
    "\n",
    "Ajouter les cellules nécessaires pour garder la trace de votre travail\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vous disposez normalement de 4 modèles de langage bigrammes et 4 modèles de langage trigrammes appris sur le même corpus. Vous allez les tester sur le même fichier de test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUTATION DES MODELES DE LANGAGE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul de la perplexité et du taux de mots hors vocabulaire. Utiliser le fichier qui se trouve dans CORPUS_TEST1 pour effectuer cette évaluation. \n",
    "\n",
    "QUESTION 10 : Evaluer chacun des 8 modèles générés précédemment en utilisant la combinaison de commandes suivante : \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# echo \"perplexity –text corpus_test -probs fichier.probs -oovs fichier.oovs -annotate fichier.annote \" | evallm –arpa # modele_a_tester\n",
    "\n",
    "#avec\n",
    "#\tevallm [ -binary .binlm | -arpa .arpa [ -context .ccs ] \n",
    "\n",
    "# exécuter les commandes d'évaluation dans un terminal, copier coller la commande et la trace "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Commenter une des traces\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSE DES RESULTATS "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 11 : Présenter sous forme de tableau ou équivalent (cf. exemple) les différents résultats obtenus (OOV, Entropie, Perplexité) et déterminer quel est le modèle a priori le plus performant.\n",
    "\n",
    "\n",
    "Méthode de prélèvement\tEvaluation Modèle Bigramme PERPLEXITE et OOV\tEvaluation Modèle Trigramme PERPLEXITE et OOV\n",
    "\n",
    "- Linear\t            ...                                             ...\n",
    "\t\n",
    "- Absolute\t            ...                                             ...\n",
    "\t\n",
    "- Good Turing\t        ...                                             ...\n",
    "\t\n",
    "- Witten Bell\t        ...                                             ...\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 12 : Consulter les différents fichiers générés (.probs, .oovs, .annote). Copier-coller les 20 premières lignes (commande head) de chaque dans une cellule texte brut et commenter. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 13 : Utiliser votre meilleur modèle bigramme et votre meilleur modèle trigramme et évaluer les sur le fichier contenu dans CORPUS_TEST2. Copier-coller les résultats et commenter.   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire un pdf de votre notebook (Ctrl P + imprimer dans un fichier) Déposer le notebook et sa version pdf sur moodle. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
