{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP N°6 MODELES DE LANGAGE STATISTIQUES\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sauvegardez le fichier en mettant votre NOM dans le nom du notebook. Ce document servira de compte rendu de TP et devra être déposé sur moodle à la fin de la séance. \n",
    "\n",
    "Après avoir récupéré et lu le sujet, répondre à chacune des questions posées en : \n",
    "1) Récupérant la commande exécutée sous ubuntu ainsi que la trace associée \n",
    "2) Commentant le résultat et/ou en apportant des éléments de réponses dans la zone de texte dédiée"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RAPPELS: les commandes à utiliser sont des lignes de commandes Unix (cf 1A). Les mécanismes de redirection sont donc utilisés pour \n",
    "(1) envoyer des données en entrée de la commande (<) (2) sauvegarder des données de sortie dans un fichier (>) (3) et \n",
    "envoyer le résultat d’une commande à la commande suivante (|). Les [] indiquent que le contenu est optionnel et que la valeur indiquée est \n",
    "la valeur par défaut. Ne pas inscrire explicitement les [] dans les commandes ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPRENTISSAGE DES MODELES DE LANGAGE N-GRAMMES"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Génération de la liste de mots et calcul du nombre d’occurrences\n",
    "\n",
    "QUESTION 1 : En utilisant l’ensemble des fichiers dédiés à l’apprentissage (CORPUS_APP), \n",
    "utiliser l’outil text2wfreq pour générer la liste des mots présents dans ces fichiers ainsi que leur nombre d’occurrences (fichier .wfreq).\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# text2wfreq \t[ -hash 1000000 ] [ -verbosity 2 ] < .text     > .wfreq\n",
    "# exécuter la commande dans un terminal, copier coller la commande et la trace et copier coller le début (10 premières # lignes commande head) \n",
    "et la fin du fichier généré (10 dernières lignes commande tail). Trop long sinon \n",
    "\n",
    "text2wfreq < concat.tlm1 > occ.wfreq\n",
    "text2wfreq : Reading text from standard input...\n",
    "text2wfreq : Done.\n",
    "\n",
    "A 1\n",
    "E 1\n",
    "J 2\n",
    "accompagn�s 1\n",
    "U 4\n",
    "V 1\n",
    "X 1\n",
    "a 158\n",
    "c 1\n",
    "d 1\n",
    "\n",
    "courageuse 1\n",
    "majoritaire 1\n",
    "combattu 1\n",
    "globale 1\n",
    "r�gles 3\n",
    "remodeler 1\n",
    "doivent 5\n",
    "optimistes 1\n",
    "Gr�gori 1\n",
    "d�plaire 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 2 : A l’aide de la commande unix sort, trier la liste de façon à la classer les mots par nombres d’occurrences décroissants.\n",
    "Quels sont les mots les plus fréquents ? A quoi correspondent-ils et pourquoi ? \n",
    "\n",
    "Les mots les plus fréquents sont <S> </S> loin devant les autres car ils correspondent aux balises de début et de fin de phrase.\n",
    "Elles sont suivies par les déterminants qui sont très fréquents en langue française.\n",
    "\n",
    "sort -n -r -k2  < occ.wfreq > occ_sorted.wfreq\n",
    "\n",
    "<S> 1277\n",
    "</S> 1277\n",
    "de 1073\n",
    "la 701\n",
    "le 611\n",
    "l' 500\n",
    "et 456\n",
    "les 454\n",
    "� 444\n",
    "en 335\n",
    "\n",
    "Abbas 1\n",
    "abattre 1\n",
    "abasourdie 1\n",
    "abandonner 1\n",
    "ab 1\n",
    "A86 1\n",
    "A4 1\n",
    "A13 1\n",
    "A11 1\n",
    "A 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Génération du vocabulaire\n",
    "\n",
    "QUESTION 3 : Utiliser l’outil wfreq2vocab pour obtenir la liste des mots distincts correspondant au vocabulaire extrait de ce corpus d’apprentissage (fichier .vocab). Examinez cette liste.\n",
    "\n",
    "# wfreq2vocab \t[ -top 20000 | -gt 10] [ -records 1000000 ] [ -verbosity 2]  < .wfreq     > .vocab\n",
    "# exécuter la commande dans un terminal, copier coller la commande et la trace et copier coller le début (10 premières # lignes commande head) et la fin du \n",
    "fichier généré (10 dernières lignes commande tail). Trop long sinon\n",
    "\n",
    "wfreq2vocab < occ.wfreq > vocabulaire.vocab\n",
    "wfreq2vocab : Will generate a vocabulary containing the most\n",
    "              frequent 20000 words. Reading wfreq stream from stdin...\n",
    "wfreq2vocab : Done\n",
    "\n",
    "## Vocab generated by v2 of the CMU-Cambridge Statistcal\n",
    "## Language Modeling toolkit.\n",
    "##\n",
    "## Includes 4797 words ##\n",
    "(et)\n",
    "-ce\n",
    "-elle\n",
    "-elles\n",
    "-il\n",
    "-ils\n",
    "\n",
    "�vocation\n",
    "�voquant\n",
    "�voquent\n",
    "�voquer\n",
    "�voqueront\n",
    "�voqu�\n",
    "�voqu�e\n",
    "�v�nement\n",
    "�tes\n",
    "�tre"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Liste des bigrammes et trigrammes et nombres d’occurrences associés\n",
    "\n",
    "QUESTION 4 : Utiliser l’outil text2wngram pour générer l’ensemble des paires de mots présentes dans le corpus d’apprentissage (fichier .wngram) \n",
    "et compter leur nombre d’occurrences. \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# text2wngram [ -n 3 ] [ -temp /usr/tmp/ ][ -chars n ] [ -words m ][ -gzip | -compress ] [ -verbosity 2 ] < .text     #  > .wngram\n",
    "# exécuter la commande dans un terminal, copier coller la commande et la trace et copier coller le début (10 premières # lignes commande head) \n",
    "et la fin du fichier généré (10 dernières lignes commande tail). Trop long sinon \n",
    "\n",
    "text2wngram -temp /home/noe/Documents/Upssitech/2A/temp/ -n 2 < concat.tlm1 > ngram.wngram\n",
    "text2wngram\n",
    "n = 2\n",
    "Number of words in buffer = 9090909\n",
    "Number of chars in buffer = 63636363\n",
    "Max number of files open at once = 20\n",
    "Temporary directory = /home/noe/Documents/Upssitech/2A/temp/\n",
    "Allocated 63636363 bytes to text buffer.\n",
    "Allocated 72727272 bytes to pointer array.\n",
    "Reading text into buffer...\n",
    "Reading text into the n-gram buffer...\n",
    "20,000 words processed for each \".\", 1,000,000 for each line.\n",
    ".\n",
    "Sorting pointer array...\n",
    "Writing out temporary file /home/noe/Documents/Upssitech/2A/temp/text2wngram.tmp.noe-Lenovo-Legion-Y530-15ICH.23652.1...\n",
    "Merging temporary files...\n",
    "Merging temp files 1 through 1...\n",
    "text2wngram : Done.\n",
    "\n",
    "\n",
    "\n",
    "(et) pourquoi 1\n",
    "-ce bien 1\n",
    "-ce l� 1\n",
    "-ce qui 4\n",
    "-elle </S> 1\n",
    "-elle jouer 1\n",
    "-elle s' 1\n",
    "-elle trouver 1\n",
    "-elles d� 1\n",
    "-elles �t� 1\n",
    "...\n",
    "�tre ouverte 1\n",
    "�tre pass�s 1\n",
    "�tre pr�sent 1\n",
    "�tre pr�ventif 1\n",
    "�tre remis 1\n",
    "�tre soign�es 1\n",
    "�tre transf�r�s 1\n",
    "�tre une 1\n",
    "�tre unique 1\n",
    "�tre � 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Quels sont les bigrammes les plus fréquents ? \n",
    "A quoi correspondent-ils ? \n",
    "\n",
    "Les bigrammes les plus fréquents sont :\n",
    "\n",
    "(et) pourquoi 1\n",
    "-ce bien 1\n",
    "-ce l� 1\n",
    "-ce qui 4\n",
    "-elle </S> 1\n",
    "-elle jouer 1\n",
    "-elle s' 1\n",
    "-elle trouver 1\n",
    "-elles d� 1\n",
    "-elles �t� 1\n",
    "\n",
    "Ils correspondent a des formules recurrentes \n",
    "dans la langue francaise ou un couple pronom + verbe."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 5 : Utiliser l’outil text2idngram pour générer une autre version de cette liste (fichier .idngram)\n",
    "et comparer le résultat avec le précédent. \n",
    "Ne pas oublier l’option (-write_ascii) pour générer le résultat sous \n",
    "forme ascii et non binaire plus difficile à lire \n",
    "mais plus efficace en terme de traitement …"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# text2idngram -vocab .vocab [ -buffer 100 ] [ -temp /usr/tmp/ ] [ -files 20 ] [ -gzip | -compress ] [ -n 3 ] \n",
    "# [ -write_ascii ] [ -fof_size 10 ] [ -verbosity 2 ]< .text > .idngram \n",
    "\n",
    "# exécuter la commande dans un terminal, copier coller la commande \n",
    "et la trace et copier coller le début (10 premières # lignes commande head) \n",
    "et la fin du fichier généré (10 dernières lignes commande tail). Trop long sinon \n",
    "\n",
    "text2idngram -vocab vocabulaire.vocab -write_ascii -temp /home/noe/Documents/Upssitech/2A/temp/ < concat.tlm1 > ngram.idngram\n",
    "text2idngram\n",
    "Vocab                  : vocabulaire.vocab\n",
    "N-gram buffer size     : 100\n",
    "Hash table size        : 200000\n",
    "Temp directory         : /home/noe/Documents/Upssitech/2A/temp/\n",
    "Max open files         : 20\n",
    "FOF size               : 10\n",
    "n                      : 3\n",
    "Initialising hash table...\n",
    "Reading vocabulary...\n",
    "Allocating memory for the n-gram buffer...\n",
    "Reading text into the n-gram buffer...\n",
    "20,000 n-grams processed for each \".\", 1,000,000 for each line.\n",
    ".\n",
    "Sorting n-grams...\n",
    "Writing sorted n-grams to temporary file /home/noe/Documents/Upssitech/2A/temp/text2idngram.temp.noe-Lenovo-Legion-Y530-15ICH.24981.1\n",
    "Merging temporary files...\n",
    "\n",
    "2-grams occurring:      N times         > N times       Sug. -spec_num value\n",
    "      0                                           16340           16513\n",
    "      1                           13291            3049            3089\n",
    "      2                            1732            1317            1340\n",
    "      3                             542             775             792\n",
    "      4                             268             507             522\n",
    "      5                             143             364             377\n",
    "      6                              92             272             284\n",
    "      7                              51             221             233\n",
    "      8                              48             173             184\n",
    "      9                              34             139             150\n",
    "     10                              20             119             130\n",
    "\n",
    "3-grams occurring:      N times         > N times       Sug. -spec_num value\n",
    "      0                                           22119           22350\n",
    "      1                           20247            1872            1900\n",
    "      2                            1265             607             623\n",
    "      3                             296             311             324\n",
    "      4                             123             188             199\n",
    "      5                              61             127             138\n",
    "      6                              35              92             102\n",
    "      7                              17              75              85\n",
    "      8                              13              62              72\n",
    "      9                              11              51              61\n",
    "     10                               5              46              56\n",
    "text2idngram : Done.\n",
    "\n",
    "1 3428 3257 1\n",
    "2 1050 3689 1\n",
    "2 2758 2658 1\n",
    "2 3670 2051 2\n",
    "2 3670 4036 1\n",
    "2 3670 4624 1\n",
    "3 17 18 1\n",
    "3 2618 4474 1\n",
    "3 3990 4762 1\n",
    "3 4449 3993 1\n",
    "...\n",
    "4797 3172 1962 1\n",
    "4797 3269 939 1\n",
    "4797 3574 3337 1\n",
    "4797 3589 2779 1\n",
    "4797 3780 4660 1\n",
    "4797 4129 2652 1\n",
    "4797 4416 4521 1\n",
    "4797 4475 4407 1\n",
    "4797 4478 17 1\n",
    "4797 4660 2652 1\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 6 : Examinez la trace affichée pendant l’exécution de la commande et commentez les éléments qui vous semblent significatifs.\n",
    "\n",
    "Les deux tableaux montrent le nombre d'occurrences de chaque n-gramme et suggèrent une valeur pour l'option \"-spec_num\".\n",
    "Cette option sert plus tard pour spécifier un nombre minimum d'occurrences pour inclure un n-gramme dans le modèle final. (voir doc)\n",
    "\n",
    "Relancer sans l’option -write_ascii pour obtenir une version binaire à utiliser par la suite (question 8).  \n",
    " Commande + trace\n",
    "\n",
    "text2idngram -vocab vocabulaire.vocab -temp /home/noe/Documents/Upssitech/2A/temp/ < concat.tlm1 > ngrambin.idngram\n",
    "text2idngram\n",
    "Vocab                  : vocabulaire.vocab\n",
    "N-gram buffer size     : 100\n",
    "Hash table size        : 200000\n",
    "Temp directory         : /home/noe/Documents/Upssitech/2A/temp/\n",
    "Max open files         : 20\n",
    "FOF size               : 10\n",
    "n                      : 3\n",
    "Initialising hash table...\n",
    "Reading vocabulary...\n",
    "Allocating memory for the n-gram buffer...\n",
    "Reading text into the n-gram buffer...\n",
    "20,000 n-grams processed for each \".\", 1,000,000 for each line.\n",
    ".\n",
    "Sorting n-grams...\n",
    "Writing sorted n-grams to temporary file /home/noe/Documents/Upssitech/2A/temp/text2idngram.temp.noe-Lenovo-Legion-Y530-15ICH.25181.1\n",
    "Merging temporary files...\n",
    "\n",
    "2-grams occurring:      N times         > N times       Sug. -spec_num value\n",
    "      0                                           16340           16513\n",
    "      1                           13291            3049            3089\n",
    "      2                            1732            1317            1340\n",
    "      3                             542             775             792\n",
    "      4                             268             507             522\n",
    "      5                             143             364             377\n",
    "      6                              92             272             284\n",
    "      7                              51             221             233\n",
    "      8                              48             173             184\n",
    "      9                              34             139             150\n",
    "     10                              20             119             130\n",
    "\n",
    "3-grams occurring:      N times         > N times       Sug. -spec_num value\n",
    "      0                                           22119           22350\n",
    "      1                           20247            1872            1900\n",
    "      2                            1265             607             623\n",
    "      3                             296             311             324\n",
    "      4                             123             188             199\n",
    "      5                              61             127             138\n",
    "      6                              35              92             102\n",
    "      7                              17              75              85\n",
    "      8                              13              62              72\n",
    "      9                              11              51              61\n",
    "     10                               5              46              56\n",
    "text2idngram : Done.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 7 : Reprendre les mêmes étapes (Q4, Q5 et Q6) mais générer les fichiers correspondants aux triplets de mots.\n",
    "Ajouter les cellules (text brut) nécessaires. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 8 : A partir du fichier .idngram binaire généré précédemment, construire un modèle de langage bigramme pour chaque méthode de prélèvement proposée. Utiliser l’outil idngram2lm et l’option –arpa pour générer un fichier au format ARPA (.arpa). "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# idngram2lm -idngram .idngram\n",
    "#           -vocab .vocab\n",
    "#           -arpa .arpa | -binary .binlm\n",
    "#         [ -context .ccs ]\n",
    "#         [ -calc_mem | -buffer 100 | -spec_num y ... z ]\n",
    "#         [ -vocab_type 1 ][ -oov_fraction 0.5 ]\n",
    "#         [ -linear | -absolute | -good_turing | -witten_bell ]\n",
    "#         [ -disc_ranges 1 7 7 ] [ -cutoffs 0 ... 0 ]\n",
    "#         [ -min_unicount 0 ][ -zeroton_fraction 1.0 ]\n",
    "#         [ -ascii_input | -bin_input ][ -n 3 ]  \n",
    "#         [ -verbosity 2 ] [ -four_byte_counts ]\n",
    "#         [ -two_byte_bo_weights\n",
    "#         [ -min_bo_weight -3.2 ] [ -max_bo_weight 2.5 ] \n",
    "#            [ -out_of_range_bo_weights 10000 ] ]\n",
    "\n",
    "Remarque : vous pouvez consulter la documentation section « Discounting strategies » pour voir les détails concernant les méthodes de prélèvement et calcul du discount ratio (delta ou d(r)). \n",
    "\n",
    "# exécuter la commande dans un terminal, copier coller la commande et la trace \n",
    "\n",
    "\n",
    "idngram2lm -vocab vocabulaire.vocab -idngram ngrambin.idngram -arpa idngram2lm.arpa\n",
    "  n : 3\n",
    "  Input file : ngrambin.idngram     (binary format)\n",
    "  Output files :\n",
    "     ARPA format   : idngram2lm.arpa\n",
    "  Vocabulary file : vocabulaire.vocab\n",
    "  Cutoffs :\n",
    "     2-gram : 0     3-gram : 0     \n",
    "  Vocabulary type : Open - type 1\n",
    "  Minimum unigram count : 0\n",
    "  Zeroton fraction : 1\n",
    "  Counts will be stored in two bytes.\n",
    "  Count table size : 65535\n",
    "  Discounting method : Good-Turing\n",
    "     Discounting ranges :\n",
    "        1-gram : 1     2-gram : 7     3-gram : 7     \n",
    "  Memory allocation for tree structure : \n",
    "     Allocate 100 MB of memory, shared equally between all n-gram tables.\n",
    "  Back-off weight storage : \n",
    "     Back-off weights will be stored in four bytes.\n",
    "Reading vocabulary.\n",
    "read_wlist_into_siht: a list of 4797 words was read from \"vocabulaire.vocab\".\n",
    "read_wlist_into_array: a list of 4797 words was read from \"vocabulaire.vocab\".\n",
    "Allocated space for 5000000 2-grams.\n",
    "Allocated space for 12500000 3-grams.\n",
    "Allocated 50000000 bytes to table for 2-grams.\n",
    "Allocated 50000000 bytes to table for 3-grams.\n",
    "Processing id n-gram file.\n",
    "20,000 n-grams processed for each \".\", 1,000,000 for each line.\n",
    ".\n",
    "Calculating discounted counts.\n",
    "Warning : 1-gram : Discounting range is 1; setting P(zeroton)=P(singleton).\n",
    "Discounted value : 1.00\n",
    "Warning : 2-gram : Some discount values are out of range;\n",
    "lowering discounting range to 6.\n",
    "Unigrams's discount mass is 3.83791e-05 (n1/N = 0.106995)\n",
    "1 zerotons, P(zeroton) = 3.83791e-05 P(singleton) = 3.83769e-05\n",
    "P(zeroton) was reduced to 0.0000383769 (1.000 of P(singleton))\n",
    "prob[UNK] = 3.83769e-05\n",
    "Incrementing contexts...\n",
    "Calculating back-off weights...\n",
    "Writing out language model...\n",
    "ARPA-style 3-gram will be written to idngram2lm.arpa\n",
    "idngram2lm : Done\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Quelles informations sont données dans la trace.\n",
    "Quelles sont celles qui vous paraissent significatives.\n",
    "Comparer les valeurs obtenues lors de la génération des différents modèles.\n",
    "Commentez ici\n",
    "\n",
    "On a :\n",
    "    Cutoffs : 2-gram : 0 3-gram : 0 : specifie que les n-grammes avec une fréquence inférieure à 0 ne seront pas considérés dans le modèle de langage.\n",
    "    \"Minimum unigram count : 0\" : specifie le nombre minimum d'occurrences qu'un mot doit avoir pour être inclus dans le modèle de langage.\n",
    "    \"Counts will be stored in two bytes.\" : specifie que les comptages des n-grammes seront stockés sur 2 octets.\n",
    "    \"Memory allocation for tree structure : Allocate 100 MB of memory, shared equally between all n-gram tables.\" : spécifie la quantité de mémoire \n",
    "    allouée pour l'arbre utilisé par le programme"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 9 : Reprendre l’étape précédente (Q8) pour générer un modèle de langage trigramme avec chacune des méthodes de prélèvement disponibles. \n",
    "\n",
    "Ajouter les cellules nécessaires pour garder la trace de votre travail\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vous disposez normalement de 4 modèles de langage bigrammes et 4 modèles de langage trigrammes appris sur le même corpus. Vous allez les tester sur le même fichier de test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUTATION DES MODELES DE LANGAGE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul de la perplexité et du taux de mots hors vocabulaire. Utiliser le fichier qui se trouve dans CORPUS_TEST1 pour effectuer cette évaluation. \n",
    "\n",
    "QUESTION 10 : Evaluer chacun des 8 modèles générés précédemment en utilisant la combinaison de commandes suivante : \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# echo \"perplexity –text corpus_test -probs fichier.probs -oovs fichier.oovs -annotate fichier.annote \" | evallm –arpa # modele_a_tester\n",
    "\n",
    "#avec\n",
    "#\tevallm [ -binary .binlm | -arpa .arpa [ -context .ccs ] \n",
    "\n",
    "# exécuter les commandes d'évaluation dans un terminal, copier coller la commande et la trace \n",
    "\n",
    "\n",
    "echo \"perplexity -text /home/noe/Documents/Upssitech/2A/Semestre_2/TAP/TP7/TP_MLS_NGRAMMES/CORPUS_TP/CORPUS_TEST1/20030416_0700_0800_FRANCEINTER_DGA.tlm1 -probs fichier.probs -oovs fichier.oovs -annotate fichtate fichier.annote \" | evallm -arpa idngram2lm.arpa\n",
    "Reading in language model from file idngram2lm.arpa\n",
    "Reading in a 3-gram language model.\n",
    "Number of 1-grams = 4798.\n",
    "Number of 2-grams = 16340.\n",
    "Number of 3-grams = 22119.\n",
    "Reading unigrams...\n",
    "\n",
    "Reading 2-grams...\n",
    "\n",
    "Reading 3-grams...\n",
    ".\n",
    "Done.\n",
    "evallm : Computing perplexity of the language model with respect\n",
    "   to the text /home/noe/Documents/Upssitech/2A/Semestre_2/TAP/TP7/TP_MLS_NGRAMMES/CORPUS_TP/CORPUS_TEST1/20030416_0700_0800_FRANCEINTER_DGA.tlm1\n",
    "Probability stream will be written to file fichier.probs\n",
    "Annotation will be written to file fichtate\n",
    "Out of vocabulary words will be written to file fichier.oovs\n",
    "Perplexity = 136.28, Entropy = 7.09 bits\n",
    "Computation based on 11049 words.\n",
    "Number of 3-grams hit = 2482  (22.46%)\n",
    "Number of 2-grams hit = 3175  (28.74%)\n",
    "Number of 1-grams hit = 5392  (48.80%)\n",
    "1857 OOVs (14.39%) and 0 context cues were removed from the calculation.\n",
    "evallm : Done."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Commenter une des traces\n",
    "\n",
    "La trace nous donne les statistiques associés au modele testé. \n",
    "On retrouve notamment la Perplexité du modele qui doit etre la plus basse possible (ici 136.28). On a aussi l'entropie du modèle\n",
    "Ensuite on trouve le nombre de 3-grammes, 2-grammes et 1-grammes qui ont été correctement prédits et le pourcentage associé avec \n",
    "le nombre total de n-grammes dans le texte.\n",
    "\n",
    "Perplexity = 136.28, Entropy = 7.09 bits\n",
    "Computation based on 11049 words.\n",
    "Number of 3-grams hit = 2482  (22.46%)\n",
    "Number of 2-grams hit = 3175  (28.74%)\n",
    "Number of 1-grams hit = 5392  (48.80%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSE DES RESULTATS "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 11 : Présenter sous forme de tableau ou équivalent (cf. exemple) les différents résultats obtenus (OOV, Entropie, Perplexité) et déterminer quel est le modèle a priori le plus performant.\n",
    "\n",
    "\n",
    "Méthode de prélèvement\tEvaluation Modèle Bigramme PERPLEXITE et OOV\tEvaluation Modèle Trigramme PERPLEXITE et OOV\n",
    "\n",
    "- Linear\t            ...                                             ...\n",
    "\t\n",
    "- Absolute\t            ...                                             ...\n",
    "\t\n",
    "- Good Turing\t        ...                                             ...\n",
    "\t\n",
    "- Witten Bell\t        ...                                             ...\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 12 : Consulter les différents fichiers générés (.probs, .oovs, .annote). Copier-coller les 20 premières lignes (commande head) de chaque dans une cellule texte brut et commenter. \n",
    "\n",
    "================\n",
    "fichier.probs\n",
    "================\n",
    "0.049023\n",
    "0.00206063\n",
    "0.413809\n",
    "0.00867561\n",
    "0.00592652\n",
    "0.0342926\n",
    "0.999309\n",
    "0.000232702\n",
    "0.273023\n",
    "0.00313401\n",
    "...\n",
    "0.551696\n",
    "0.353102\n",
    "0.618016\n",
    "0.00940373\n",
    "0.916643\n",
    "0.0673442\n",
    "0.68691\n",
    "0.0903858\n",
    "0.68691\n",
    "0.0100369\n",
    "\n",
    "================\n",
    "fichier.oovs\n",
    "================\n",
    "commandes\n",
    "Paoli\n",
    "Stoufflet\n",
    "m'en\n",
    "partez\n",
    "conversation\n",
    "t�l�phonique\n",
    "brouille\n",
    "persister\n",
    "divergences\n",
    "...\n",
    "averses\n",
    "afficher\n",
    "Tours\n",
    "Alsace\n",
    "Nice\n",
    "ensoleill�\n",
    "P�ques\n",
    "rafra�chir\n",
    "d�grader\n",
    "a�e\n",
    "\n",
    "================\n",
    "fichier.annote\n",
    "================\n",
    "P( <S> | ) = 0.049023 logprob = -1.309600 bo_case = 1\n",
    "P( bonne | <S> ) = 0.00206063 logprob = -2.686000 bo_case = 2\n",
    "P( journ�e | <S> bonne ) = 0.413809 logprob = -0.383200 bo_case = 3\n",
    "P( � | bonne journ�e ) = 0.00867561 logprob = -2.061700 bo_case = 3-2-1\n",
    "P( tous | journ�e � ) = 0.00592652 logprob = -2.227200 bo_case = 3x2\n",
    "P( </S> | � tous ) = 0.0342926 logprob = -1.464800 bo_case = 3-2-1\n",
    "P( <S> | tous </S> ) = 0.999309 logprob = -0.000300 bo_case = 3x2\n",
    "P( Fabrice | </S> <S> ) = 0.000232702 logprob = -3.633200 bo_case = 3-2-1\n",
    "P( Drouelle | <S> Fabrice ) = 0.273023 logprob = -0.563800 bo_case = 3x2\n",
    "P( est | Fabrice Drouelle ) = 0.00313401 logprob = -2.503900 bo_case = 3-2-1\n",
    "...\n",
    "P( Collado | merci Jo�l ) = 0.551696 logprob = -0.258300 bo_case = 3\n",
    "P( </S> | Jo�l Collado ) = 0.353102 logprob = -0.452100 bo_case = 3\n",
    "P( <S> | Collado </S> ) = 0.618016 logprob = -0.209000 bo_case = 3\n",
    "P( France | </S> <S> ) = 0.00940373 logprob = -2.026700 bo_case = 3\n",
    "P( Inter | <S> France ) = 0.916643 logprob = -0.037800 bo_case = 3\n",
    "P( il | France Inter ) = 0.0673442 logprob = -1.171700 bo_case = 3\n",
    "P( est | Inter il ) = 0.68691 logprob = -0.163100 bo_case = 3\n",
    "P( huit | il est ) = 0.0903858 logprob = -1.043900 bo_case = 3\n",
    "P( heures | est huit ) = 0.68691 logprob = -0.163100 bo_case = 3\n",
    "P( </S> | huit heures ) = 0.0100369 logprob = -1.998400 bo_case = 3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUESTION 13 : Utiliser votre meilleur modèle bigramme et votre meilleur modèle trigramme et évaluer les sur le fichier contenu dans CORPUS_TEST2.\n",
    "Copier-coller les résultats et commenter.   \n",
    "\n",
    "echo \"perplexity -text /home/noe/Documents/Upssitech/2A/Semestre_2/TAP/TP7/TP_MLS_NGRAMMES/CORPUS_TP/CORPUS_TEST2/20030418_1700_1800_FRANCEINFO_DGA.dev.tlm1 -probs fichier.probs -oovs fichier.oovs -annotate fichier.annote \" | evallm -arpa idngram2lm.arpa\n",
    "Reading in language model from file idngram2lm.arpa\n",
    "Reading in a 3-gram language model.\n",
    "Number of 1-grams = 4798.\n",
    "Number of 2-grams = 16340.\n",
    "Number of 3-grams = 22119.\n",
    "Reading unigrams...\n",
    "\n",
    "Reading 2-grams...\n",
    "\n",
    "Reading 3-grams...\n",
    ".\n",
    "Done.\n",
    "evallm : Computing perplexity of the language model with respect\n",
    "   to the text /home/noe/Documents/Upssitech/2A/Semestre_2/TAP/TP7/TP_MLS_NGRAMMES/CORPUS_TP/CORPUS_TEST2/20030418_1700_1800_FRANCEINFO_DGA.dev.tlm1\n",
    "Probability stream will be written to file fichier.probs\n",
    "Annotation will be written to file fichier.annote\n",
    "Out of vocabulary words will be written to file fichier.oovs\n",
    "Perplexity = 181.85, Entropy = 7.51 bits\n",
    "Computation based on 10130 words.\n",
    "Number of 3-grams hit = 1375  (13.57%)\n",
    "Number of 2-grams hit = 3222  (31.81%)\n",
    "Number of 1-grams hit = 5533  (54.62%)\n",
    "2170 OOVs (17.64%) and 0 context cues were removed from the calculation.\n",
    "evallm : Done.\n",
    "\n",
    "\n",
    "J'ai pas le temps de tester avec d'autre modèle mais ce qui est sûr c'est que ce modèle est mauvais. Surtout pour la prédiction de 3 et 2 grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire un pdf de votre notebook (Ctrl P + imprimer dans un fichier) Déposer le notebook et sa version pdf sur moodle. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
